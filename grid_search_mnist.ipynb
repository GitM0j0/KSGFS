{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "grid_search_mnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "METc8j7hXK28",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import os\n",
        "\n",
        "# from itertools import chain\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "from torch._utils import _accumulate\n",
        "from torch.utils.data.dataset import Subset\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.rcParams.update({'font.size': 22})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ER1UdVILXtu_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "50447418-add6-4cb4-d4ee-ac5d1f7be1fe"
      },
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x5c798000 @  0x7fdcde2241c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\r\n",
            "0.4.0\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BzFyp_5lX8M4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9903fa47-4f8e-44ca-fac1-ea9ee49e1a12"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install torchvision"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\r\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\r\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.4.0)\r\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.5)\r\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.2.0)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eWm1HDgBXK3A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "dataset_size = 55000\n",
        "validation_size = 5000\n",
        "test_size = 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zlGXZ3FzXK3E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def random_split(dataset, lengths):\n",
        "    \"\"\"\n",
        "    Randomly split a dataset into non-overlapping new datasets of given lengths.\n",
        "\n",
        "    Arguments:\n",
        "        dataset (Dataset): Dataset to be split\n",
        "        lengths (sequence): lengths of splits to be produced\n",
        "    \"\"\"\n",
        "    if sum(lengths) != len(dataset):\n",
        "        raise ValueError(\"Sum of input lengths does not equal the length of the input dataset!\")\n",
        "\n",
        "    indices = torch.randperm(sum(lengths))\n",
        "    return [Subset(dataset, indices[offset - length:offset]) for offset, length in zip(_accumulate(lengths), lengths)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sgdM0ACiXK3H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "3bb197a4-cce8-4591-eb44-b10776758607"
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Load MNIST training set\n",
        "train_data = torchvision.datasets.MNIST(root=os.environ.get(\"DATASETS_PATH\", \"~/datasets\"), train=True,\n",
        "                                         download=True, transform=transforms.ToTensor())\n",
        "\n",
        "# Split training set into training and validation set\n",
        "train_data, validation_data = random_split(train_data,[dataset_size, validation_size])\n",
        "# Load MNIST test set\n",
        "test_data = torchvision.datasets.MNIST(root=os.environ.get(\"DATASETS_PATH\", \"~/datasets\"), train=False,\n",
        "                                        download=True, transform=transforms.ToTensor())\n",
        "\n",
        "# Put datasets into data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=0)\n",
        "val_loader = torch.utils.data.DataLoader(validation_data, batch_size=validation_size, num_workers=0)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=test_size, num_workers=0)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tHT-bQWAXK3K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "                      nn.Linear(784, 400, bias=True),\n",
        "                      nn.SELU(),\n",
        "                      nn.Linear(400, 400, bias=True),\n",
        "                      nn.SELU(),\n",
        "                      nn.Linear(400, 400, bias=True),\n",
        "                      nn.SELU(),\n",
        "                      nn.Linear(400,10, bias=True)\n",
        "                    ).to(device)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.model(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DVNlmX3doWOk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "54b73bff-2c05-4d63-afb3-642f6c7baa3b"
      },
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "X9RcDX1MXK3N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class evaluation(object):\n",
        "    def __init__(self, test_data, criterion):\n",
        "        self.test_data = test_data\n",
        "        self.criterion = criterion\n",
        "        self.n = 0\n",
        "        self.avg_prediction = 0.\n",
        "\n",
        "    def acc(self, model):\n",
        "\n",
        "        with torch.autograd.no_grad():\n",
        "            self.n += 1\n",
        "            for x, y in iter(self.test_data):\n",
        "                x = x.view(x.size(0), -1)\n",
        "                x = x.to(device)\n",
        "                y = y.to(device)\n",
        "                predictions = model(x)\n",
        "                self.avg_prediction = self.avg_prediction * (self.n - 1.) / self.n + predictions / self.n\n",
        "\n",
        "                loss = self.criterion(self.avg_prediction, y)\n",
        "                acc = 100 * (self.avg_prediction.argmax(1) == y).float().sum() / x.shape[0]\n",
        "\n",
        "        return loss, acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wwxgRFzFj-q5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PtDaRQhZj-th",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J32Nr1I_XeoP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from enum import Enum\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class sgld(object):\n",
        "\n",
        "    def __init__(self, network, lr, lambda_, batch_size, dataset_size):\n",
        "        self.network = network\n",
        "        self.n = batch_size\n",
        "        self.N = dataset_size\n",
        "        self.linear_layers = [m for m in self.network.modules() if isinstance (m, nn.Linear)]\n",
        "        self.lr_init = lr\n",
        "        self.lambda_ = lambda_\n",
        "        self.t = 1.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def step(self,):\n",
        "        learning_rate = self.lr_init * 0.5 ** (self.t // 10000)\n",
        "        for l in self.linear_layers:\n",
        "            likelihood_grad = l.weight.grad\n",
        "            prior_grad = l.weight.data\n",
        "            if l.bias is not None:\n",
        "                bias_grad = l.bias.grad\n",
        "                likelihood_grad = torch.cat((likelihood_grad, bias_grad.unsqueeze(1)), 1)\n",
        "                prior_grad = torch.cat((prior_grad, l.bias.data.unsqueeze(1)), 1)\n",
        "\n",
        "            likelihood_grad *= float(self.N) / self.n\n",
        "\n",
        "\n",
        "            posterior_grad = likelihood_grad.add(self.lambda_, prior_grad)\n",
        "            noise = torch.randn_like(posterior_grad) * math.sqrt(learning_rate)\n",
        "            update = (learning_rate * posterior_grad).add_(noise)\n",
        "\n",
        "            if l.bias is not None:\n",
        "                l.weight.data.add_(-update[:, :-1])\n",
        "                l.bias.data.add_(-update[:, -1])\n",
        "            else:\n",
        "                l.weight.data.add_(-update)\n",
        "        self.t +=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QhVA8ooYXK3Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "d65c432e-ea2d-493f-f73f-8e9bf3d342df"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "\n",
        "# Model parameter\n",
        "lambda_ = 1.\n",
        "#lr = 3e-6\n",
        "\n",
        "#learning_rates = [1e-6, 1e-7, 1e-8]\n",
        "#learning_rates = [3e-6, 2e-6, 1e-6, 9e-7, 8e-7, 7e-7, 6e-7, 5e-7]\n",
        "#learning_rates = [3e-6]\n",
        "learning_rates = [2e-6]\n",
        "\n",
        "t = 1\n",
        "n = 0\n",
        "\n",
        "#error_results = []\n",
        "losses_sgld = []\n",
        "acc_sgld = []\n",
        "for lr in learning_rates:\n",
        "    network = Model()\n",
        "    criterion = nn.CrossEntropyLoss(size_average=False)\n",
        "    optim = sgld(network, lr, lambda_, batch_size, dataset_size)\n",
        "    evaluate = evaluation(test_loader, criterion)\n",
        "    for epoch in range(25):\n",
        "        running_loss = 0\n",
        "        for x, y in iter(train_loader):\n",
        "            x = x.view(x.size(0), -1)\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            network.zero_grad()\n",
        "            output = network(x)\n",
        "            loss = criterion(output, y)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "            running_loss += loss * batch_size / dataset_size\n",
        "            prediction = output.data.max(1)[1]\n",
        "            accuracy = torch.sum(prediction.eq(y)).float()/batch_size\n",
        "\n",
        "\n",
        "            if (t >= 300) & (t % 100 == 0):\n",
        "                loss, acc = evaluate.acc(network)\n",
        "                losses_sgld.append(loss)\n",
        "                acc_sgld.append(acc)\n",
        "\n",
        "\n",
        "            t += 1.\n",
        "\n",
        "\n",
        "\n",
        "        print(\"Epoch {:d} - loss: {:.4f} - acc: {:.4f}\".format(epoch, running_loss, accuracy))\n",
        "\n",
        "    #error_sgld = 100. - acc\n",
        "    #print(error_sgld)\n",
        "    #error_results.append(error_sgld)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 - loss: 42.5379 - acc: 0.9100\n",
            "Epoch 1 - loss: 26.8964 - acc: 0.9400\n",
            "Epoch 2 - loss: 18.7595 - acc: 0.9500\n",
            "Epoch 3 - loss: 14.6478 - acc: 0.9500\n",
            "Epoch 4 - loss: 12.7381 - acc: 0.9600\n",
            "Epoch 5 - loss: 11.1794 - acc: 0.9600\n",
            "Epoch 6 - loss: 10.0574 - acc: 0.9500\n",
            "Epoch 7 - loss: 9.2856 - acc: 0.9700\n",
            "Epoch 8 - loss: 8.9695 - acc: 0.9900\n",
            "Epoch 9 - loss: 9.0629 - acc: 0.9800\n",
            "Epoch 10 - loss: 8.6770 - acc: 0.9700\n",
            "Epoch 11 - loss: 8.8417 - acc: 0.9500\n",
            "Epoch 12 - loss: 8.3022 - acc: 0.9800\n",
            "Epoch 13 - loss: 8.7621 - acc: 0.9700\n",
            "Epoch 14 - loss: 7.9398 - acc: 0.9700\n",
            "Epoch 15 - loss: 9.4037 - acc: 0.9900\n",
            "Epoch 16 - loss: 8.7894 - acc: 0.9800\n",
            "Epoch 17 - loss: 9.2472 - acc: 0.9800\n",
            "Epoch 18 - loss: 4.7222 - acc: 0.9900\n",
            "Epoch 19 - loss: 2.1387 - acc: 1.0000\n",
            "Epoch 20 - loss: 2.0349 - acc: 0.9900\n",
            "Epoch 21 - loss: 2.3188 - acc: 1.0000\n",
            "Epoch 22 - loss: 2.2252 - acc: 1.0000\n",
            "Epoch 23 - loss: 2.3344 - acc: 1.0000\n",
            "Epoch 24 - loss: 2.7830 - acc: 0.9900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FHbiDXaz8Cgc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.save(\"mnist_accSGLD.npy\",acc_sgld)\n",
        "np.save(\"mnist_lossSGLD.npy\",losses_sgld)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hNZJ6Qdd9Qen",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f58974e7-ac3a-4b02-df28-f4f7386b69e9"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "print( os.getcwd() )\n",
        "print( os.listdir() )"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "['.config', 'sample_data', 'mnist_accKSGFS.npy', 'mnist_lossKSGFS.npy', 'mnist_accpKSGFS.npy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i82_J6gc9iP5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download( \"mnist_accSGLD.npy\" )  \n",
        "files.download( \"mnist_lossSGLD.npy\" )  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eRvmWO_1XK3X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c89526a6-8789-49d1-8953-12ba9f67cd64"
      },
      "cell_type": "code",
      "source": [
        "error_results\n",
        "# 2e-6"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(1.8200, device='cuda:0')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "wpPPi6ERgNZ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "788586f9-96db-4bd0-f51a-e6cebcc24903"
      },
      "cell_type": "code",
      "source": [
        "acc_sgld = np.load('mnist_accSGLD.npy')\n",
        "loss_sgld = np.load('mnist_lossSGLD.npy')\n",
        "acc_psgld = np.load('mnist_accpSGLD.npy')\n",
        "loss_psgld = np.load('mnist_losspSGLD.npy')\n",
        "\n",
        "acc_ksgfs = np.load('mnist_accpKSGFS.npy')\n",
        "loss_ksgfs = np.load('mnist_lossKSGFS.npy')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-2d163186af03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc_sgld\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist_accSGLD.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mloss_sgld\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist_lossSGLD.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0macc_psgld\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist_accpSGLD.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss_psgld\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist_losspSGLD.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mnist_accSGLD.npy'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "fhC-PCW6XK3Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "8faa78ec-86bd-41c7-ae58-ae284cbeb045"
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,9))\n",
        "#plt.plot(range(len(acc_sgld)),acc_sgld, label=\"SGLD\")\n",
        "#plt.plot(range(len(acc_psgld)),acc_psgld, label=\"pSGLD\", color='red')\n",
        "plt.plot(range(len(acc_ksgfs)),acc_ksgfs, label=\"K-SGFS\", color='green')\n",
        "plt.plot(range(len(acc_ksgld)),acc_ksgld, label=\"K-SGFS\", color='yellow')\n",
        "plt.plot\n",
        "plt.ylim(90,100)\n",
        "plt.xlabel('Number of Samples')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f6434183828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAIaCAYAAADr+GE3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f6487b457b8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "rdjC3pDvfYpb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from enum import Enum\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class psgld(object):\n",
        "    ### pSGLD with RMSProp as preconditioner\n",
        "\n",
        "    def __init__(self, network, lr, alpha, lambda_, batch_size, dataset_size):\n",
        "        self.network = network\n",
        "        self.n = batch_size\n",
        "        self.N = dataset_size\n",
        "        self.linear_layers = [m for m in self.network.modules() if isinstance (m, nn.Linear)]\n",
        "        self.lr_init = lr\n",
        "        self.alpha = alpha\n",
        "        self.lambda_ = lambda_\n",
        "        self.t = 1.\n",
        "\n",
        "        self.square_avg = dict()\n",
        "\n",
        "    def step(self,):\n",
        "        learning_rate = self.lr_init * 0.5 ** (self.t // 10000)\n",
        "        for l in self.linear_layers:\n",
        "            likelihood_grad = l.weight.grad\n",
        "            prior_grad = l.weight.data\n",
        "            if l.bias is not None:\n",
        "                likelihood_grad = torch.cat((likelihood_grad, l.bias.grad.unsqueeze(1)), 1)\n",
        "                prior_grad = torch.cat((prior_grad, l.bias.data.unsqueeze(1)), 1)\n",
        "\n",
        "            likelihood_grad *= float(self.N) / self.n\n",
        "\n",
        "            posterior_grad = likelihood_grad.add(self.lambda_, prior_grad)\n",
        "\n",
        "            if self.t == 1:\n",
        "                self.square_avg[l] = torch.zeros_like(posterior_grad)\n",
        "\n",
        "            self.square_avg[l].mul_(self.alpha).addcmul_(1. - self.alpha, likelihood_grad, likelihood_grad)\n",
        "            avg = self.square_avg[l].sqrt().add_(1e-4)\n",
        "            noise = torch.randn_like(posterior_grad)\n",
        "\n",
        "\n",
        "            update = (learning_rate * 0.5 * torch.div(posterior_grad, avg)).addcdiv_(math.sqrt(learning_rate), noise, avg.sqrt())\n",
        "\n",
        "\n",
        "            if l.bias is not None:\n",
        "                l.weight.data.add_(-1, update[:, :-1])\n",
        "                l.bias.data.add_(-1, update[:, -1])\n",
        "            else:\n",
        "                l.weight.data.add_(-1, update)\n",
        "\n",
        "        self.t +=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yWxX0vdWXK3f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "8a996b1e-0fb5-435d-8298-76bd70984d42"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "\n",
        "# Model parameter\n",
        "lambda_ = 1.\n",
        "#lr = 3e-6\n",
        "\n",
        "#learning_rates = [4e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9]\n",
        "#learning_rates = [4e-3, 3e-3, 2e-3, 1e-3, 9e-3, 8e-3, 7e-3, 6e-5, 5e-5]\n",
        "learning_rates = [4e-4]\n",
        "alpha = 0.99\n",
        "\n",
        "\n",
        "t = 1.\n",
        "n = 0.\n",
        "\n",
        "error_psgld = []\n",
        "losses_psgld = []\n",
        "acc_psgld = []\n",
        "for lr in learning_rates:\n",
        "    network = Model()\n",
        "    criterion = nn.CrossEntropyLoss(size_average=False)\n",
        "    optim = psgld(network, lr, alpha, lambda_, batch_size, dataset_size)\n",
        "    evaluate = evaluation(test_loader, criterion)\n",
        "    for epoch in range(25):\n",
        "        running_loss = 0\n",
        "        for x, y in iter(train_loader):\n",
        "            x = x.view(x.size(0), -1)\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            network.zero_grad()\n",
        "            output = network(x)\n",
        "            loss = criterion(output, y)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "            running_loss += loss * batch_size / dataset_size\n",
        "            prediction = output.data.max(1)[1]\n",
        "            accuracy = torch.sum(prediction.eq(y)).float()/batch_size\n",
        "\n",
        "\n",
        "            if (t >= 300) & (t % 100 == 0):\n",
        "                loss, acc = evaluate.acc(network)\n",
        "                losses_psgld.append(loss)\n",
        "                acc_psgld.append(acc)\n",
        "\n",
        "\n",
        "            t += 1.\n",
        "\n",
        "    #     losses_psgld.append(loss)\n",
        "    #     acc_psgld.append(acc)\n",
        "\n",
        "        print(\"Epoch {:d} - loss: {:.4f} - acc: {:.4f}\".format(epoch, running_loss, accuracy))\n",
        "\n",
        "    error = 100. - acc\n",
        "    print(error)\n",
        "    error_psgld.append(error)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 - loss: 38.0347 - acc: 0.9300\n",
            "Epoch 1 - loss: 25.0518 - acc: 0.9500\n",
            "Epoch 2 - loss: 19.3185 - acc: 0.9500\n",
            "Epoch 3 - loss: 15.5969 - acc: 0.9600\n",
            "Epoch 4 - loss: 13.5469 - acc: 0.9600\n",
            "Epoch 5 - loss: 12.2951 - acc: 0.9600\n",
            "Epoch 6 - loss: 11.0892 - acc: 0.9600\n",
            "Epoch 7 - loss: 10.5837 - acc: 0.9500\n",
            "Epoch 8 - loss: 9.8929 - acc: 0.9500\n",
            "Epoch 9 - loss: 9.3612 - acc: 0.9800\n",
            "Epoch 10 - loss: 8.7391 - acc: 0.9900\n",
            "Epoch 11 - loss: 8.1907 - acc: 0.9900\n",
            "Epoch 12 - loss: 8.0519 - acc: 0.9600\n",
            "Epoch 13 - loss: 7.7994 - acc: 0.9500\n",
            "Epoch 14 - loss: 7.3934 - acc: 1.0000\n",
            "Epoch 15 - loss: 7.5682 - acc: 0.9700\n",
            "Epoch 16 - loss: 6.7709 - acc: 0.9800\n",
            "Epoch 17 - loss: 7.1237 - acc: 0.9600\n",
            "Epoch 18 - loss: 5.0832 - acc: 0.9900\n",
            "Epoch 19 - loss: 4.0295 - acc: 1.0000\n",
            "Epoch 20 - loss: 4.1521 - acc: 0.9700\n",
            "Epoch 21 - loss: 4.2246 - acc: 0.9900\n",
            "Epoch 22 - loss: 3.8858 - acc: 0.9800\n",
            "Epoch 23 - loss: 4.1154 - acc: 0.9800\n",
            "Epoch 24 - loss: 4.0699 - acc: 0.9900\n",
            "tensor(2.6700, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nnddIgk9H6IS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.save(\"mnist_accpSGLD.npy\",acc_psgld)\n",
        "np.save(\"mnist_losspSGLD.npy\",losses_psgld)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sHzdQ79zi_9d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download( \"mnist_accpSGLD.npy\" )  \n",
        "files.download( \"mnist_losspSGLD.npy\" ) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aUNlrtOTjH4o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2312
        },
        "outputId": "d924c057-80f7-4d26-96d1-9155cf1a13a3"
      },
      "cell_type": "code",
      "source": [
        "acc_psgld"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(90.6800, device='cuda:0'),\n",
              " tensor(91.8600, device='cuda:0'),\n",
              " tensor(92.2700, device='cuda:0'),\n",
              " tensor(92.6900, device='cuda:0'),\n",
              " tensor(92.8500, device='cuda:0'),\n",
              " tensor(92.9800, device='cuda:0'),\n",
              " tensor(93.2400, device='cuda:0'),\n",
              " tensor(93.4400, device='cuda:0'),\n",
              " tensor(93.7000, device='cuda:0'),\n",
              " tensor(93.9300, device='cuda:0'),\n",
              " tensor(94.1000, device='cuda:0'),\n",
              " tensor(94.1900, device='cuda:0'),\n",
              " tensor(94.4100, device='cuda:0'),\n",
              " tensor(94.5300, device='cuda:0'),\n",
              " tensor(94.6500, device='cuda:0'),\n",
              " tensor(94.6800, device='cuda:0'),\n",
              " tensor(94.7800, device='cuda:0'),\n",
              " tensor(94.9200, device='cuda:0'),\n",
              " tensor(95.0500, device='cuda:0'),\n",
              " tensor(95.1700, device='cuda:0'),\n",
              " tensor(95.2700, device='cuda:0'),\n",
              " tensor(95.4300, device='cuda:0'),\n",
              " tensor(95.5200, device='cuda:0'),\n",
              " tensor(95.5500, device='cuda:0'),\n",
              " tensor(95.6200, device='cuda:0'),\n",
              " tensor(95.7200, device='cuda:0'),\n",
              " tensor(95.8600, device='cuda:0'),\n",
              " tensor(95.9100, device='cuda:0'),\n",
              " tensor(95.9100, device='cuda:0'),\n",
              " tensor(96.0600, device='cuda:0'),\n",
              " tensor(96.0700, device='cuda:0'),\n",
              " tensor(96.1400, device='cuda:0'),\n",
              " tensor(96.1300, device='cuda:0'),\n",
              " tensor(96.2100, device='cuda:0'),\n",
              " tensor(96.2500, device='cuda:0'),\n",
              " tensor(96.2700, device='cuda:0'),\n",
              " tensor(96.3600, device='cuda:0'),\n",
              " tensor(96.4000, device='cuda:0'),\n",
              " tensor(96.4300, device='cuda:0'),\n",
              " tensor(96.4300, device='cuda:0'),\n",
              " tensor(96.4400, device='cuda:0'),\n",
              " tensor(96.5700, device='cuda:0'),\n",
              " tensor(96.5700, device='cuda:0'),\n",
              " tensor(96.6000, device='cuda:0'),\n",
              " tensor(96.6300, device='cuda:0'),\n",
              " tensor(96.6400, device='cuda:0'),\n",
              " tensor(96.6500, device='cuda:0'),\n",
              " tensor(96.6800, device='cuda:0'),\n",
              " tensor(96.7300, device='cuda:0'),\n",
              " tensor(96.7500, device='cuda:0'),\n",
              " tensor(96.7200, device='cuda:0'),\n",
              " tensor(96.7400, device='cuda:0'),\n",
              " tensor(96.7500, device='cuda:0'),\n",
              " tensor(96.7300, device='cuda:0'),\n",
              " tensor(96.7900, device='cuda:0'),\n",
              " tensor(96.8600, device='cuda:0'),\n",
              " tensor(96.9200, device='cuda:0'),\n",
              " tensor(96.9300, device='cuda:0'),\n",
              " tensor(96.9500, device='cuda:0'),\n",
              " tensor(96.9700, device='cuda:0'),\n",
              " tensor(96.9900, device='cuda:0'),\n",
              " tensor(96.9900, device='cuda:0'),\n",
              " tensor(97., device='cuda:0'),\n",
              " tensor(97.0200, device='cuda:0'),\n",
              " tensor(97.0200, device='cuda:0'),\n",
              " tensor(97.0200, device='cuda:0'),\n",
              " tensor(97.0500, device='cuda:0'),\n",
              " tensor(97.0900, device='cuda:0'),\n",
              " tensor(97.0700, device='cuda:0'),\n",
              " tensor(97.0600, device='cuda:0'),\n",
              " tensor(97.0600, device='cuda:0'),\n",
              " tensor(97.0700, device='cuda:0'),\n",
              " tensor(97.0600, device='cuda:0'),\n",
              " tensor(97.0700, device='cuda:0'),\n",
              " tensor(97.0800, device='cuda:0'),\n",
              " tensor(97.0500, device='cuda:0'),\n",
              " tensor(97.0800, device='cuda:0'),\n",
              " tensor(97.0900, device='cuda:0'),\n",
              " tensor(97.1300, device='cuda:0'),\n",
              " tensor(97.1200, device='cuda:0'),\n",
              " tensor(97.1600, device='cuda:0'),\n",
              " tensor(97.1800, device='cuda:0'),\n",
              " tensor(97.1900, device='cuda:0'),\n",
              " tensor(97.2500, device='cuda:0'),\n",
              " tensor(97.2600, device='cuda:0'),\n",
              " tensor(97.2600, device='cuda:0'),\n",
              " tensor(97.2500, device='cuda:0'),\n",
              " tensor(97.2500, device='cuda:0'),\n",
              " tensor(97.2600, device='cuda:0'),\n",
              " tensor(97.2400, device='cuda:0'),\n",
              " tensor(97.2400, device='cuda:0'),\n",
              " tensor(97.2500, device='cuda:0'),\n",
              " tensor(97.2300, device='cuda:0'),\n",
              " tensor(97.2300, device='cuda:0'),\n",
              " tensor(97.2400, device='cuda:0'),\n",
              " tensor(97.2400, device='cuda:0'),\n",
              " tensor(97.2400, device='cuda:0'),\n",
              " tensor(97.2800, device='cuda:0'),\n",
              " tensor(97.2500, device='cuda:0'),\n",
              " tensor(97.2500, device='cuda:0'),\n",
              " tensor(97.2700, device='cuda:0'),\n",
              " tensor(97.2800, device='cuda:0'),\n",
              " tensor(97.2700, device='cuda:0'),\n",
              " tensor(97.2800, device='cuda:0'),\n",
              " tensor(97.2700, device='cuda:0'),\n",
              " tensor(97.2700, device='cuda:0'),\n",
              " tensor(97.2400, device='cuda:0'),\n",
              " tensor(97.2300, device='cuda:0'),\n",
              " tensor(97.2300, device='cuda:0'),\n",
              " tensor(97.2200, device='cuda:0'),\n",
              " tensor(97.2400, device='cuda:0'),\n",
              " tensor(97.2400, device='cuda:0'),\n",
              " tensor(97.2500, device='cuda:0'),\n",
              " tensor(97.2500, device='cuda:0'),\n",
              " tensor(97.2500, device='cuda:0'),\n",
              " tensor(97.2600, device='cuda:0'),\n",
              " tensor(97.2500, device='cuda:0'),\n",
              " tensor(97.2400, device='cuda:0'),\n",
              " tensor(97.2500, device='cuda:0'),\n",
              " tensor(97.2500, device='cuda:0'),\n",
              " tensor(97.2600, device='cuda:0'),\n",
              " tensor(97.2400, device='cuda:0'),\n",
              " tensor(97.2500, device='cuda:0'),\n",
              " tensor(97.2700, device='cuda:0'),\n",
              " tensor(97.2500, device='cuda:0'),\n",
              " tensor(97.2600, device='cuda:0'),\n",
              " tensor(97.2700, device='cuda:0'),\n",
              " tensor(97.2800, device='cuda:0'),\n",
              " tensor(97.3000, device='cuda:0'),\n",
              " tensor(97.3100, device='cuda:0'),\n",
              " tensor(97.3100, device='cuda:0'),\n",
              " tensor(97.3300, device='cuda:0'),\n",
              " tensor(97.3400, device='cuda:0'),\n",
              " tensor(97.3500, device='cuda:0'),\n",
              " tensor(97.3300, device='cuda:0')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "aq8WxHqq7BLS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from enum import Enum\n",
        "\n",
        "import scipy.linalg as la\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "class BackpropMode(Enum):\n",
        "    STANDARD = 0\n",
        "    CURVATURE = 1\n",
        "\n",
        "\n",
        "class KSGLD(object):\n",
        "\n",
        "    def __init__(self, net, criterion, batch_size, dataset_size, eta=1., v=0., lambda_=1e-3, epsilon=1e-3, l2=1e-3, invert_every=1):\n",
        "        if not isinstance(criterion, (nn.CrossEntropyLoss, nn.BCEWithLogitsLoss, nn.MSELoss)):\n",
        "            raise ValueError(\"Unrecognized loss:\", criterion.__class__.__name__)\n",
        "\n",
        "\n",
        "        self.net = net\n",
        "        self.criterion = criterion\n",
        "        self.invert_every = invert_every\n",
        "        self.inversion_counter = -1\n",
        "\n",
        "\n",
        "        self.n = batch_size\n",
        "        self.N = dataset_size\n",
        "        self.epsilon= epsilon\n",
        "\n",
        "\n",
        "        self.eta = eta\n",
        "        self.v = v\n",
        "        self.lambda_ = lambda_\n",
        "        self.l2 = l2\n",
        "\n",
        "        self.mode = BackpropMode.STANDARD\n",
        "\n",
        "        self.linear_layers = [m for m in self.net.modules() if isinstance(m, nn.Linear)]\n",
        "\n",
        "        self.input_covariances = dict()\n",
        "        self.preactivation_fishers = dict()\n",
        "        self.preactivations = dict()\n",
        "        self.preactivation_fisher_inverses = dict()\n",
        "        self.input_covariance_inverses = dict()\n",
        "\n",
        "        self.t = 1.\n",
        "\n",
        "        self._add_hooks_to_net()\n",
        "\n",
        "    def update_curvature(self, x):\n",
        "        self.mode = BackpropMode.CURVATURE\n",
        "\n",
        "        output = self.net(x)\n",
        "        preacts = [self.preactivations[l] for l in self.linear_layers]\n",
        "        if isinstance(self.criterion, nn.CrossEntropyLoss):\n",
        "            p = F.softmax(output, 1).detach()\n",
        "            label_sample = torch.multinomial(p, 1, out=p.new(p.size(0)).long()).squeeze()\n",
        "            loss_fun = F.cross_entropy\n",
        "        elif isinstance(self.criterion, nn.MSELoss):\n",
        "            p = output.detach()\n",
        "            label_sample = torch.normal(p, 1.)\n",
        "            loss_fun = lambda x, y, **kwargs: 0.5 * F.mse_loss(x, y, **kwargs).sum(1)\n",
        "        elif isinstance(self.criterion, nn.BCEWithLogitsLoss):\n",
        "            p = output.detach()\n",
        "            p = F.sigmoid(p)\n",
        "            label_sample = torch.bernoulli(p)\n",
        "            loss_fun = lambda x, y, **kwargs: F.binary_cross_entropy_with_logits(x, y, **kwargs).sum(1)\n",
        "        else:\n",
        "            raise NotImplemented\n",
        "\n",
        "        l = sum(loss_fun(output, label_sample, reduce=False))\n",
        "        preact_grads = torch.autograd.grad(l, preacts)\n",
        "        scale = p.size(0) ** -1\n",
        "        for pg, mod in zip(preact_grads, self.linear_layers):\n",
        "            preact_fisher = pg.t().mm(pg).detach() * scale\n",
        "            self._update_factor(self.preactivation_fishers, mod, preact_fisher)\n",
        "\n",
        "        self.mode = BackpropMode.STANDARD\n",
        "\n",
        "        self.inversion_counter += 1\n",
        "        if self.inversion_counter % self.invert_every == 0:\n",
        "            self.inversion_counter = 0\n",
        "            self.invert_curvature()\n",
        "\n",
        "    def invert_curvature(self):\n",
        "        self._invert_fn(self.preactivation_fishers, self.preactivation_fisher_inverses)\n",
        "        self._invert_fn(self.input_covariances, self.input_covariance_inverses)\n",
        "\n",
        "    def _invert_fn(self, d, inv_dict):\n",
        "        for mod, mat in d.items():\n",
        "            l, u = map(mat.new, la.eigh(mat.cpu().numpy()))\n",
        "\n",
        "            \n",
        "            inv = (u * ((l + self.lambda_) ** -1)).mm(u.t())\n",
        "            inv_dict[mod] = inv\n",
        "\n",
        "    def _linear_forward_hook(self, mod, inputs, output):\n",
        "        if self.mode == BackpropMode.CURVATURE:\n",
        "            self.preactivations[mod] = output\n",
        "            inp = inputs[0]\n",
        "            scale = output.size(0) ** -1\n",
        "            if mod.bias is not None:\n",
        "                inp = torch.cat((inp, inp.new(inp.size(0), 1).fill_(1)), 1)\n",
        "            input_cov = inp.t().mm(inp).detach() * scale\n",
        "            self._update_factor(self.input_covariances, mod, input_cov)\n",
        "\n",
        "    def _update_factor(self, d, mod, mat):\n",
        "        if mod not in d or (self.v == 0 and self.eta == 1):\n",
        "            d[mod] = mat\n",
        "        else:\n",
        "            d[mod] = self.v * d[mod] + self.eta * mat\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        for l in self.linear_layers:\n",
        "            likelihood_grad = l.weight.grad\n",
        "            prior_grad = l.weight.data\n",
        "            if l.bias is not None:\n",
        "                bias_grad = l.bias.grad\n",
        "                likelihood_grad = torch.cat((likelihood_grad, bias_grad.unsqueeze(1)), 1)\n",
        "                prior_grad = torch.cat((l.weight.data, l.bias.data.unsqueeze(1)), 1)\n",
        "\n",
        "            likelihood_grad *= float(self.N) / self.n\n",
        "\n",
        "            posterior_grad = likelihood_grad.add(self.lambda_, prior_grad)\n",
        "\n",
        "            noise = torch.randn_like(posterior_grad)\n",
        "\n",
        "            A_inv = self.input_covariance_inverses[l]\n",
        "            G_inv = self.preactivation_fisher_inverses[l]\n",
        "\n",
        "            nat_grad = G_inv.mm(posterior_grad).mm(A_inv)\n",
        "\n",
        "            A_inv_ch = torch.potrf(A_inv)\n",
        "            G_inv_ch = torch.potrf(G_inv, upper=False)\n",
        "\n",
        "            noise_precon = G_inv_ch.mm(noise).mm(A_inv_ch)\n",
        "\n",
        "            eps = self.epsilon * 0.5 ** (self.t // 10000) \n",
        "            learning_rate = eps * 0.5 * float(self.N) / self.n\n",
        "            noise_factor = math.sqrt(eps * float(self.n) / self.N)\n",
        "\n",
        "            update = (learning_rate *  nat_grad).add(noise_factor, noise_precon)\n",
        "\n",
        "            if l.bias is not None:\n",
        "                l.weight.data.add_(-1, update[:, :-1])\n",
        "                l.bias.data.add_(-1, update[:, -1])\n",
        "            else:\n",
        "                l.weight.data.add_(-1, update)\n",
        "        self.t += 1\n",
        "\n",
        "    def _add_hooks_to_net(self):\n",
        "        def register_hook(m):\n",
        "            if isinstance(m, nn.Linear):\n",
        "                m.register_forward_hook(self._linear_forward_hook)\n",
        "\n",
        "        self.net.apply(register_hook)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U-PgXa0M7BSz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "dc85f08e-4946-4fa5-db6f-6b806117cd28"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "\n",
        "# Model parameter\n",
        "\n",
        "#lr = 3e-6\n",
        "\n",
        "#learning_rates = [1e-1, 1e-2, 1e-3, 1e-4]\n",
        "#learning_rates = [5e-2, 4e-2, 3e-2, 2e-2, 1e-2, 9e-3, 8e-3, 7e-3, 6e-3, 5e-3]\n",
        "learning_rates = [4e-7]\n",
        "\n",
        "eta = 1.\n",
        "v = 0\n",
        "lambda_ = 1.\n",
        "l2 = 1e-3\n",
        "\n",
        "\n",
        "t = 1\n",
        "n = 0\n",
        "\n",
        "error_ksgld = []\n",
        "losses_ksgld = []\n",
        "acc_ksgld = []\n",
        "for lr in learning_rates:\n",
        "    network = Model()\n",
        "    criterion = nn.CrossEntropyLoss(size_average=False)\n",
        "    optim = KSGLD(network, criterion, batch_size, dataset_size, eta=eta, v=v, lambda_=lambda_, epsilon=lr, l2=l2, invert_every=1)\n",
        "    evaluate = evaluation(test_loader, criterion)\n",
        "    for epoch in range(25):\n",
        "        running_loss = 0\n",
        "        for x, y in iter(train_loader):\n",
        "            x = x.view(x.size(0), -1)\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            \n",
        "            optim.update_curvature(x)\n",
        "\n",
        "            network.zero_grad()\n",
        "            output = network(x)\n",
        "            loss = criterion(output, y)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "            running_loss += loss * batch_size / dataset_size\n",
        "            prediction = output.data.max(1)[1]\n",
        "            accuracy = torch.sum(prediction.eq(y)).float()/batch_size\n",
        "\n",
        "\n",
        "            if (t >= 300) & (t % 100 == 0):\n",
        "                with torch.autograd.no_grad():\n",
        "                    for x,y in iter(test_loader):\n",
        "                        loss, acc = evaluate.acc(network)\n",
        "                        losses_ksgld.append(loss)\n",
        "                        acc_ksgld.append(acc)\n",
        "                        \n",
        "\n",
        "            t += 1.\n",
        "\n",
        "    #     losses_psgld.append(loss)\n",
        "    #     acc_psgld.append(acc)\n",
        "\n",
        "        print(\"Epoch {:d} - loss: {:.4f} - acc: {:.4f}\".format(epoch, running_loss, accuracy))\n",
        "\n",
        "    error = 100. - acc\n",
        "    print(error)\n",
        "    error_ksgld.append(error)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 - loss: 131.3690 - acc: 0.9500\n",
            "Epoch 1 - loss: 22.0295 - acc: 0.9600\n",
            "Epoch 2 - loss: 17.4569 - acc: 0.9700\n",
            "Epoch 3 - loss: 14.8613 - acc: 0.9700\n",
            "Epoch 4 - loss: 10.1928 - acc: 0.9700\n",
            "Epoch 5 - loss: 7.5079 - acc: 0.9900\n",
            "Epoch 6 - loss: 7.8191 - acc: 0.9900\n",
            "Epoch 7 - loss: 8.3293 - acc: 0.9800\n",
            "Epoch 8 - loss: 6.9378 - acc: 0.9800\n",
            "Epoch 9 - loss: 7.4143 - acc: 0.9900\n",
            "Epoch 10 - loss: 4.4740 - acc: 1.0000\n",
            "Epoch 11 - loss: 4.1582 - acc: 0.9800\n",
            "Epoch 12 - loss: 5.3106 - acc: 1.0000\n",
            "Epoch 13 - loss: 4.9817 - acc: 0.9800\n",
            "Epoch 14 - loss: 3.0719 - acc: 0.9900\n",
            "Epoch 15 - loss: 3.2727 - acc: 0.9900\n",
            "Epoch 16 - loss: 3.4595 - acc: 0.9900\n",
            "Epoch 17 - loss: 3.4793 - acc: 0.9900\n",
            "Epoch 18 - loss: 1.3609 - acc: 1.0000\n",
            "Epoch 19 - loss: 0.2384 - acc: 1.0000\n",
            "Epoch 20 - loss: 0.0500 - acc: 1.0000\n",
            "Epoch 21 - loss: 0.0322 - acc: 1.0000\n",
            "Epoch 22 - loss: 0.0335 - acc: 1.0000\n",
            "Epoch 23 - loss: 0.0363 - acc: 1.0000\n",
            "Epoch 24 - loss: 0.0396 - acc: 1.0000\n",
            "tensor(1.5600, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s02nV87zeZW2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95a3ee06-98bf-4efe-8755-f878539959ad"
      },
      "cell_type": "code",
      "source": [
        "len(acc_ksgld)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "135"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "cv7GQYm6edlz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.save(\"mnist_accKSGLD.npy\",acc_ksgld)\n",
        "np.save(\"mnist_lossKSGLD.npy\",losses_ksgld)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aYWitl9eedsR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download( \"mnist_accKSGLD.npy\" )  \n",
        "files.download( \"mnist_lossKSGLD.npy\" )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "krhLaGhTZgtn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from enum import Enum\n",
        "\n",
        "import scipy.linalg as la\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "class BackpropMode(Enum):\n",
        "    STANDARD = 0\n",
        "    CURVATURE = 1\n",
        "\n",
        "\n",
        "class KSGFS(object):\n",
        "\n",
        "    def __init__(self, net, criterion, batch_size, dataset_size, eta=1., v=0., lambda_=1e-3, epsilon=1e-3, l2=1e-3, invert_every=1):\n",
        "        if not isinstance(criterion, (nn.CrossEntropyLoss, nn.BCEWithLogitsLoss, nn.MSELoss)):\n",
        "            raise ValueError(\"Unrecognized loss:\", criterion.__class__.__name__)\n",
        "\n",
        "\n",
        "        self.net = net\n",
        "        self.criterion = criterion\n",
        "        self.invert_every = invert_every\n",
        "        self.inversion_counter = -1\n",
        "\n",
        "\n",
        "        self.n = batch_size\n",
        "        self.N = dataset_size\n",
        "        self.gamma = float(dataset_size + batch_size) / batch_size\n",
        "        self.learning_rate = 2. / (self.gamma * float(self.N) / self.n  + 4. * float(self.N) / (epsilon * self.n))\n",
        "        self.noise_factor = 2. * math.sqrt(float(self.N) / (epsilon * self.n))\n",
        "\n",
        "        #self.learning_rate = 2. / (self.gamma * (1.  + 4. / (epsilon)))\n",
        "        #self.noise_factor = 2. * math.sqrt(self.gamma / (epsilon))\n",
        "        self.eta = eta\n",
        "        self.v = v\n",
        "        self.lambda_ = lambda_\n",
        "        self.l2 = l2\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "        self.mode = BackpropMode.STANDARD\n",
        "\n",
        "        self.linear_layers = [m for m in self.net.modules() if isinstance(m, nn.Linear)]\n",
        "\n",
        "        self.input_covariances = dict()\n",
        "        self.preactivation_fishers = dict()\n",
        "        self.preactivations = dict()\n",
        "        self.preactivation_fisher_inverses = dict()\n",
        "        self.input_covariance_inverses = dict()\n",
        "\n",
        "        self.t = 1.\n",
        "\n",
        "        self._add_hooks_to_net()\n",
        "\n",
        "    def update_curvature(self, x):\n",
        "        self.mode = BackpropMode.CURVATURE\n",
        "\n",
        "        output = self.net(x)\n",
        "        preacts = [self.preactivations[l] for l in self.linear_layers]\n",
        "        if isinstance(self.criterion, nn.CrossEntropyLoss):\n",
        "            p = F.softmax(output, 1).detach()\n",
        "            label_sample = torch.multinomial(p, 1, out=p.new(p.size(0)).long()).squeeze()\n",
        "            loss_fun = F.cross_entropy\n",
        "        elif isinstance(self.criterion, nn.MSELoss):\n",
        "            p = output.detach()\n",
        "            label_sample = torch.normal(p, 1.)\n",
        "            loss_fun = lambda x, y, **kwargs: 0.5 * F.mse_loss(x, y, **kwargs).sum(1)\n",
        "        elif isinstance(self.criterion, nn.BCEWithLogitsLoss):\n",
        "            p = output.detach()\n",
        "            p = F.sigmoid(p)\n",
        "            label_sample = torch.bernoulli(p)\n",
        "            loss_fun = lambda x, y, **kwargs: F.binary_cross_entropy_with_logits(x, y, **kwargs).sum(1)\n",
        "        else:\n",
        "            raise NotImplemented\n",
        "\n",
        "        l = sum(loss_fun(output, label_sample, reduce=False))\n",
        "        preact_grads = torch.autograd.grad(l, preacts)\n",
        "        scale = p.size(0) ** -1\n",
        "        for pg, mod in zip(preact_grads, self.linear_layers):\n",
        "            preact_fisher = pg.t().mm(pg).detach() * scale\n",
        "            self._update_factor(self.preactivation_fishers, mod, preact_fisher)\n",
        "\n",
        "        self.mode = BackpropMode.STANDARD\n",
        "\n",
        "        self.inversion_counter += 1\n",
        "        if self.inversion_counter % self.invert_every == 0:\n",
        "            self.inversion_counter = 0\n",
        "            self.invert_curvature()\n",
        "\n",
        "    def invert_curvature(self):\n",
        "        self._invert_fn(self.preactivation_fishers, self.preactivation_fisher_inverses)\n",
        "        self._invert_fn(self.input_covariances, self.input_covariance_inverses)\n",
        "\n",
        "    def _invert_fn(self, d, inv_dict):\n",
        "        for mod, mat in d.items():\n",
        "            l, u = map(mat.new, la.eigh(mat.cpu().numpy()))\n",
        "            #l = l.to(device)\n",
        "            #u = u.to(device)\n",
        "            \n",
        "            inv = (u * ((l + self.lambda_) ** -1)).mm(u.t())\n",
        "            inv_dict[mod] = inv\n",
        "\n",
        "    def _linear_forward_hook(self, mod, inputs, output):\n",
        "        if self.mode == BackpropMode.CURVATURE:\n",
        "            self.preactivations[mod] = output\n",
        "            inp = inputs[0]\n",
        "            scale = output.size(0) ** -1\n",
        "            if mod.bias is not None:\n",
        "                inp = torch.cat((inp, inp.new(inp.size(0), 1).fill_(1)), 1)\n",
        "            input_cov = inp.t().mm(inp).detach() * scale\n",
        "            self._update_factor(self.input_covariances, mod, input_cov)\n",
        "\n",
        "    def _update_factor(self, d, mod, mat):\n",
        "        if mod not in d or (self.v == 0 and self.eta == 1):\n",
        "            d[mod] = mat\n",
        "        else:\n",
        "            d[mod] = self.v * d[mod] + self.eta * mat\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        for l in self.linear_layers:\n",
        "            likelihood_grad = l.weight.grad\n",
        "            prior_grad = l.weight.data\n",
        "            if l.bias is not None:\n",
        "                bias_grad = l.bias.grad\n",
        "                likelihood_grad = torch.cat((likelihood_grad, bias_grad.unsqueeze(1)), 1)\n",
        "                prior_grad = torch.cat((l.weight.data, l.bias.data.unsqueeze(1)), 1)\n",
        "\n",
        "            likelihood_grad *= float(self.N) / self.n\n",
        "\n",
        "            posterior_grad = likelihood_grad.add(self.lambda_, prior_grad)\n",
        "\n",
        "            noise = torch.randn_like(posterior_grad)\n",
        "\n",
        "            # Small epsilon to stabilise computation of Cholesky factors\n",
        "            eps = 1e-4\n",
        "            A_ch = torch.potrf(self.input_covariances[l].add(eps, torch.eye(noise.size(1),device=device)))\n",
        "            G_ch = torch.potrf(self.preactivation_fishers[l].add(eps, torch.eye(noise.size(0),device=device)), upper=False)\n",
        "            noise_precon = G_ch.mm(noise).mm(A_ch)\n",
        "\n",
        "            posterior_grad.add_(self.noise_factor, noise_precon)\n",
        "\n",
        "            A_inv = self.input_covariance_inverses[l]\n",
        "            G_inv = self.preactivation_fisher_inverses[l]\n",
        "            update = self.learning_rate * G_inv.mm(posterior_grad).mm(A_inv)\n",
        "\n",
        "            if l.bias is not None:\n",
        "                l.weight.data.add_(-1, update[:, :-1])\n",
        "                l.bias.data.add_(-1, update[:, -1])\n",
        "            else:\n",
        "                l.weight.data.add_(-1, update)\n",
        "        self.t += 1\n",
        "\n",
        "    def _add_hooks_to_net(self):\n",
        "        def register_hook(m):\n",
        "            if isinstance(m, nn.Linear):\n",
        "                m.register_forward_hook(self._linear_forward_hook)\n",
        "\n",
        "        self.net.apply(register_hook)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ou8YcAkDXK3i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "0f8fc0d5-6098-4b1b-ce44-101f472d15bb"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "\n",
        "# Model parameter\n",
        "\n",
        "#lr = 3e-6\n",
        "\n",
        "#learning_rates = [1e-1, 1e-2, 1e-3, 1e-4]\n",
        "#learning_rates = [5e-2, 4e-2, 3e-2, 2e-2, 1e-2, 9e-3, 8e-3, 7e-3, 6e-3, 5e-3]\n",
        "learning_rates = [8e-2]\n",
        "#learning_rates = [1e-2]\n",
        "\n",
        "eta = 1.\n",
        "v = 0\n",
        "lambda_ = 1.\n",
        "l2 = 1e-3\n",
        "\n",
        "\n",
        "t = 1\n",
        "n = 0\n",
        "\n",
        "error_ksgfs = []\n",
        "losses_ksgfs = []\n",
        "acc_ksgfs = []\n",
        "for lr in learning_rates:\n",
        "    network = Model()\n",
        "    criterion = nn.CrossEntropyLoss(size_average=False)\n",
        "    optim = KSGFS(network, criterion, batch_size, dataset_size, eta=eta, v=v, lambda_=lambda_, epsilon=lr, l2=l2, invert_every=1)\n",
        "    evaluate = evaluation(val_loader, criterion)\n",
        "    for epoch in range(25):\n",
        "        running_loss = 0\n",
        "        for x, y in iter(train_loader):\n",
        "            x = x.view(x.size(0), -1)\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            \n",
        "            optim.update_curvature(x)\n",
        "\n",
        "            network.zero_grad()\n",
        "            output = network(x)\n",
        "            loss = criterion(output, y)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "            running_loss += loss * batch_size / dataset_size\n",
        "            prediction = output.data.max(1)[1]\n",
        "            accuracy = torch.sum(prediction.eq(y)).float()/batch_size\n",
        "\n",
        "\n",
        "            if (t >= 300) & (t % 100 == 0):\n",
        "                with torch.autograd.no_grad():\n",
        "                    for x,y in iter(test_loader):\n",
        "                        loss, acc = evaluate.acc(network)\n",
        "                        losses_ksgfs.append(loss)\n",
        "                        acc_ksgfs.append(acc)\n",
        "                        \n",
        "\n",
        "            t += 1.\n",
        "\n",
        "    #     losses_psgld.append(loss)\n",
        "    #     acc_psgld.append(acc)\n",
        "\n",
        "        print(\"Epoch {:d} - loss: {:.4f} - acc: {:.4f}\".format(epoch, running_loss, accuracy))\n",
        "\n",
        "    error = 100. - acc\n",
        "    print(error)\n",
        "    error_ksgfs.append(error)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 - loss: 36.2115 - acc: 0.9300\n",
            "Epoch 1 - loss: 22.7741 - acc: 0.9600\n",
            "Epoch 2 - loss: 17.4424 - acc: 0.9700\n",
            "Epoch 3 - loss: 13.1174 - acc: 0.9700\n",
            "Epoch 4 - loss: 10.2086 - acc: 0.9700\n",
            "Epoch 5 - loss: 8.1392 - acc: 0.9700\n",
            "Epoch 6 - loss: 6.5113 - acc: 0.9800\n",
            "Epoch 7 - loss: 5.2051 - acc: 0.9900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-6690635cc2b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdataset_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-ce832605010c>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mA_ch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpotrf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_covariances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mG_ch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpotrf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreactivation_fishers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0mnoise_precon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG_ch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_ch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "41xqfKgTXK3l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2312
        },
        "outputId": "1c30bca1-f0fe-437a-8d4c-d86678a516cc"
      },
      "cell_type": "code",
      "source": [
        "acc_ksgfs"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(91.3000, device='cuda:0'),\n",
              " tensor(92.0400, device='cuda:0'),\n",
              " tensor(92.5000, device='cuda:0'),\n",
              " tensor(92.4800, device='cuda:0'),\n",
              " tensor(92.8800, device='cuda:0'),\n",
              " tensor(93.1600, device='cuda:0'),\n",
              " tensor(93.1400, device='cuda:0'),\n",
              " tensor(93.4400, device='cuda:0'),\n",
              " tensor(93.6400, device='cuda:0'),\n",
              " tensor(93.7800, device='cuda:0'),\n",
              " tensor(93.9400, device='cuda:0'),\n",
              " tensor(94.2800, device='cuda:0'),\n",
              " tensor(94.5200, device='cuda:0'),\n",
              " tensor(94.6200, device='cuda:0'),\n",
              " tensor(94.8400, device='cuda:0'),\n",
              " tensor(95.0200, device='cuda:0'),\n",
              " tensor(95.2200, device='cuda:0'),\n",
              " tensor(95.3600, device='cuda:0'),\n",
              " tensor(95.5000, device='cuda:0'),\n",
              " tensor(95.5400, device='cuda:0'),\n",
              " tensor(95.6400, device='cuda:0'),\n",
              " tensor(95.7600, device='cuda:0'),\n",
              " tensor(95.9000, device='cuda:0'),\n",
              " tensor(95.9600, device='cuda:0'),\n",
              " tensor(96.0600, device='cuda:0'),\n",
              " tensor(96.1600, device='cuda:0'),\n",
              " tensor(96.2200, device='cuda:0'),\n",
              " tensor(96.3200, device='cuda:0'),\n",
              " tensor(96.3800, device='cuda:0'),\n",
              " tensor(96.4600, device='cuda:0'),\n",
              " tensor(96.5200, device='cuda:0'),\n",
              " tensor(96.5200, device='cuda:0'),\n",
              " tensor(96.5600, device='cuda:0'),\n",
              " tensor(96.5800, device='cuda:0'),\n",
              " tensor(96.6000, device='cuda:0'),\n",
              " tensor(96.6400, device='cuda:0'),\n",
              " tensor(96.7400, device='cuda:0'),\n",
              " tensor(96.7000, device='cuda:0'),\n",
              " tensor(96.7200, device='cuda:0'),\n",
              " tensor(96.7800, device='cuda:0'),\n",
              " tensor(96.8200, device='cuda:0'),\n",
              " tensor(96.8200, device='cuda:0'),\n",
              " tensor(96.8000, device='cuda:0'),\n",
              " tensor(96.8200, device='cuda:0'),\n",
              " tensor(96.8200, device='cuda:0'),\n",
              " tensor(96.8200, device='cuda:0'),\n",
              " tensor(96.8400, device='cuda:0'),\n",
              " tensor(96.8200, device='cuda:0'),\n",
              " tensor(96.8200, device='cuda:0'),\n",
              " tensor(96.8200, device='cuda:0'),\n",
              " tensor(96.8800, device='cuda:0'),\n",
              " tensor(96.9200, device='cuda:0'),\n",
              " tensor(96.9600, device='cuda:0'),\n",
              " tensor(96.9800, device='cuda:0'),\n",
              " tensor(97.0200, device='cuda:0'),\n",
              " tensor(97., device='cuda:0'),\n",
              " tensor(97.0400, device='cuda:0'),\n",
              " tensor(97.0400, device='cuda:0'),\n",
              " tensor(97.0600, device='cuda:0'),\n",
              " tensor(97.0800, device='cuda:0'),\n",
              " tensor(97.0800, device='cuda:0'),\n",
              " tensor(97.1000, device='cuda:0'),\n",
              " tensor(97.1200, device='cuda:0'),\n",
              " tensor(97.1400, device='cuda:0'),\n",
              " tensor(97.1600, device='cuda:0'),\n",
              " tensor(97.1400, device='cuda:0'),\n",
              " tensor(97.1200, device='cuda:0'),\n",
              " tensor(97.1000, device='cuda:0'),\n",
              " tensor(97.1400, device='cuda:0'),\n",
              " tensor(97.1400, device='cuda:0'),\n",
              " tensor(97.1600, device='cuda:0'),\n",
              " tensor(97.2000, device='cuda:0'),\n",
              " tensor(97.1800, device='cuda:0'),\n",
              " tensor(97.2000, device='cuda:0'),\n",
              " tensor(97.2000, device='cuda:0'),\n",
              " tensor(97.1800, device='cuda:0'),\n",
              " tensor(97.1800, device='cuda:0'),\n",
              " tensor(97.1800, device='cuda:0'),\n",
              " tensor(97.1800, device='cuda:0'),\n",
              " tensor(97.2000, device='cuda:0'),\n",
              " tensor(97.2200, device='cuda:0'),\n",
              " tensor(97.2200, device='cuda:0'),\n",
              " tensor(97.2200, device='cuda:0'),\n",
              " tensor(97.2200, device='cuda:0'),\n",
              " tensor(97.2000, device='cuda:0'),\n",
              " tensor(97.2200, device='cuda:0'),\n",
              " tensor(97.2400, device='cuda:0'),\n",
              " tensor(97.2600, device='cuda:0'),\n",
              " tensor(97.2600, device='cuda:0'),\n",
              " tensor(97.3000, device='cuda:0'),\n",
              " tensor(97.3000, device='cuda:0'),\n",
              " tensor(97.3200, device='cuda:0'),\n",
              " tensor(97.3000, device='cuda:0'),\n",
              " tensor(97.3000, device='cuda:0'),\n",
              " tensor(97.3000, device='cuda:0'),\n",
              " tensor(97.3000, device='cuda:0'),\n",
              " tensor(97.2600, device='cuda:0'),\n",
              " tensor(97.3000, device='cuda:0'),\n",
              " tensor(97.2800, device='cuda:0'),\n",
              " tensor(97.3200, device='cuda:0'),\n",
              " tensor(97.3200, device='cuda:0'),\n",
              " tensor(97.3200, device='cuda:0'),\n",
              " tensor(97.3400, device='cuda:0'),\n",
              " tensor(97.3400, device='cuda:0'),\n",
              " tensor(97.3600, device='cuda:0'),\n",
              " tensor(97.3600, device='cuda:0'),\n",
              " tensor(97.3600, device='cuda:0'),\n",
              " tensor(97.3600, device='cuda:0'),\n",
              " tensor(97.4000, device='cuda:0'),\n",
              " tensor(97.4000, device='cuda:0'),\n",
              " tensor(97.4000, device='cuda:0'),\n",
              " tensor(97.4000, device='cuda:0'),\n",
              " tensor(97.4000, device='cuda:0'),\n",
              " tensor(97.4000, device='cuda:0'),\n",
              " tensor(97.4000, device='cuda:0'),\n",
              " tensor(97.4000, device='cuda:0'),\n",
              " tensor(97.3800, device='cuda:0'),\n",
              " tensor(97.4000, device='cuda:0'),\n",
              " tensor(97.4000, device='cuda:0'),\n",
              " tensor(97.4000, device='cuda:0'),\n",
              " tensor(97.4000, device='cuda:0'),\n",
              " tensor(97.4000, device='cuda:0'),\n",
              " tensor(97.4000, device='cuda:0'),\n",
              " tensor(97.3800, device='cuda:0'),\n",
              " tensor(97.3800, device='cuda:0'),\n",
              " tensor(97.3800, device='cuda:0'),\n",
              " tensor(97.3800, device='cuda:0'),\n",
              " tensor(97.3800, device='cuda:0'),\n",
              " tensor(97.3800, device='cuda:0'),\n",
              " tensor(97.3800, device='cuda:0'),\n",
              " tensor(97.3800, device='cuda:0'),\n",
              " tensor(97.3800, device='cuda:0'),\n",
              " tensor(97.3800, device='cuda:0'),\n",
              " tensor(97.3800, device='cuda:0'),\n",
              " tensor(97.3800, device='cuda:0')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "metadata": {
        "id": "EmmrYP9N1cyp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.save(\"mnist_accKSGFS.npy\",acc_ksgfs)\n",
        "np.save(\"mnist_lossKSGFS.npy\",losses_ksgfs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RrBGyW7d1c1Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download( \"mnist_accKSGFS.npy\" )  \n",
        "files.download( \"mnist_lossKSGFS.npy\" )"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}